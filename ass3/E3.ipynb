{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1953, 3072)\n",
      "(1953,)\n",
      "Done loading training data, using time:(min) 0.06249371767044067\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "time_start = time.time()\n",
    "X = np.genfromtxt('00_Data/train_X_dog_cat.csv', delimiter=',')\n",
    "y = np.genfromtxt('00_Data/train_y_dog_cat.csv', delimiter=',')\n",
    "print(X.shape)\n",
    "\n",
    "n = X.shape[0]\n",
    "d = X.shape[1]\n",
    "print(y.shape)\n",
    "time_end = time.time()\n",
    "print(\"Done loading training data, using time:(min)\", (time_end-time_start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "X_test = np.genfromtxt('00_Data/test_X_dog_cat.csv', delimiter=',')\n",
    "y_test = np.genfromtxt('00_Data/test_y_dog_cat.csv', delimiter=',')\n",
    "m = X_test.shape[0]\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(x1,x2):\n",
    "    # x1 = (n,d) X2 = (m,d)\n",
    "    return(np.dot(x1,x2.T))\n",
    "\n",
    "def inhomogeneous_poly_kernel(x1,x2):\n",
    "    n = x1.shape[0]\n",
    "    m = x2.shape[0]\n",
    "    return(np.power(np.ones(shape=(n,m)) + np.dot(x1,x2.T), 5))\n",
    "\n",
    "def gaussian_kernel(x1,x2):\n",
    "    from sklearn.gaussian_process.kernels import RBF\n",
    "    return(RBF()(x1,x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(ans, y):\n",
    "    right = 0\n",
    "    num = ans.shape[0]\n",
    "    for i in range(ans.shape[0]):\n",
    "        if (ans[i] - 0.5)*y[i] > 0:\n",
    "            right += 1\n",
    "    return(right/float(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tolerable(delta,tol):\n",
    "    from numpy import linalg as LA\n",
    "    if LA.norm(delta,1) > tol:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(alpha, Ki):\n",
    "    s = np.dot(alpha, Ki)\n",
    "    return(1/(1+np.exp(-s)))\n",
    "\n",
    "def train(K,y,max_iter,regu_para, eta,tol):\n",
    "    time_start = time.time()\n",
    "    #alpha = np.random.uniform(size=(n))\n",
    "    alpha = np.zeros(n)\n",
    "    for t in range(max_iter):\n",
    "        samples = np.random.permutation(n)[:batch_size]\n",
    "        g = regu_para * alpha\n",
    "        #g = np.zeros(n)\n",
    "        for i in samples:\n",
    "            pi = probability(alpha, K[i])\n",
    "            g[i] = g[i] + (pi - (y[i]+1)/2.0)\n",
    "        alpha = alpha - eta*g\n",
    "        if tolerable(g, tol):\n",
    "            break\n",
    "        if t % 100 == 0:\n",
    "            print(\"============== %d =================\" % t)\n",
    "            print(\"alpha:\", alpha)\n",
    "            print(\"train_accuracy:\",evaluation(probability(alpha,K), y))\n",
    "    time_end = time.time()\n",
    "    print(\"Done training, using time:(min)\", \n",
    "          (time_end-time_start)/60)\n",
    "    return(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(kernel, X,y,X_test,y_test,regu_para, eta, max_iter=50000, batch_size=640):\n",
    "    K = kernel(X,X_scaled)\n",
    "    K_test = kernel(X,X_test)\n",
    "    regu_para = 2.0\n",
    "    eta = 0.001\n",
    "    tol = 0.01\n",
    "    alpha = train(K,y, max_iter,regu_para, eta,tol)\n",
    "    print(\"Done training\")\n",
    "    print(alpha)\n",
    "    print(\"training result\")\n",
    "    ans = probability(alpha,K)\n",
    "    print(ans)\n",
    "    print(evaluation(ans, y))\n",
    "    print(\"test result\")\n",
    "    ans = probability(alpha,K_test)\n",
    "    print(ans)\n",
    "    print(evaluation(ans, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== 0 =================\n",
      "alpha: [-0.0005  0.      0.     ...  0.0005  0.      0.    ]\n",
      "train_accuracy: 0.5202252944188428\n",
      "============== 100 =================\n",
      "alpha: [-0.00293835 -0.01973765 -0.02821809 ...  0.02570185  0.02077341\n",
      "  0.02998518]\n",
      "train_accuracy: 0.5192012288786483\n",
      "============== 200 =================\n",
      "alpha: [-0.00241005 -0.04428172 -0.04264285 ...  0.03898995  0.047769\n",
      "  0.04913684]\n",
      "train_accuracy: 0.5263696876600102\n",
      "============== 300 =================\n",
      "alpha: [-0.00433871 -0.06089966 -0.05332393 ...  0.05579073  0.06266677\n",
      "  0.06474206]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 400 =================\n",
      "alpha: [-0.00961388 -0.07067441 -0.06669776 ...  0.06919193  0.07117133\n",
      "  0.07665978]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 500 =================\n",
      "alpha: [-0.0184963  -0.07843941 -0.06418814 ...  0.0781083   0.08345807\n",
      "  0.08536764]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 600 =================\n",
      "alpha: [-0.03844859 -0.08768363 -0.05362499 ...  0.08865056  0.08902669\n",
      "  0.092448  ]\n",
      "train_accuracy: 0.5376344086021505\n",
      "============== 700 =================\n",
      "alpha: [-0.04278443 -0.0959061  -0.04731228 ...  0.09623844  0.0925329\n",
      "  0.09551301]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 800 =================\n",
      "alpha: [-0.04596004 -0.09415752 -0.04026316 ...  0.10261544  0.10195421\n",
      "  0.09918567]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 900 =================\n",
      "alpha: [-0.05364721 -0.09257357 -0.03406746 ...  0.10214519  0.10693263\n",
      "  0.10809563]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 1000 =================\n",
      "alpha: [-0.06037638 -0.09325213 -0.02808201 ...  0.10338193  0.10837267\n",
      "  0.11300405]\n",
      "train_accuracy: 0.5371223758320532\n",
      "============== 1100 =================\n",
      "alpha: [-0.06498811 -0.10268416 -0.02561019 ...  0.11094131  0.11327537\n",
      "  0.11784827]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 1200 =================\n",
      "alpha: [-0.07287702 -0.09954061 -0.02232656 ...  0.11813552  0.11362399\n",
      "  0.12573676]\n",
      "train_accuracy: 0.5422427035330261\n",
      "============== 1300 =================\n",
      "alpha: [-0.08234042 -0.10883868 -0.01930009 ...  0.12364643  0.12095813\n",
      "  0.12673457]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 1400 =================\n",
      "alpha: [-0.08924948 -0.1111015  -0.01780883 ...  0.12294515  0.1237398\n",
      "  0.11909886]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 1500 =================\n",
      "alpha: [-0.09198704 -0.10611012 -0.01654756 ...  0.12324177  0.12746938\n",
      "  0.12354395]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 1600 =================\n",
      "alpha: [-0.09517515 -0.11076013 -0.0145433  ...  0.12514913  0.1226489\n",
      "  0.12483107]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 1700 =================\n",
      "alpha: [-0.09021499 -0.11049576 -0.01370652 ...  0.12419729  0.1299965\n",
      "  0.12591389]\n",
      "train_accuracy: 0.5412186379928315\n",
      "============== 1800 =================\n",
      "alpha: [-0.08438221 -0.1145981  -0.01161738 ...  0.12496215  0.13193237\n",
      "  0.12479044]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 1900 =================\n",
      "alpha: [-0.08463345 -0.11543372 -0.01031953 ...  0.12308465  0.13167664\n",
      "  0.12307947]\n",
      "train_accuracy: 0.5314900153609831\n",
      "============== 2000 =================\n",
      "alpha: [-0.08609427 -0.11859167 -0.00976824 ...  0.12642488  0.12758936\n",
      "  0.12036564]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 2100 =================\n",
      "alpha: [-0.08693934 -0.11362222 -0.00891623 ...  0.12900654  0.12794442\n",
      "  0.11926912]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 2200 =================\n",
      "alpha: [-0.08800074 -0.11279875 -0.00820025 ...  0.12909327  0.12822539\n",
      "  0.12431421]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 2300 =================\n",
      "alpha: [-0.08921287 -0.11946484 -0.00826207 ...  0.13369984  0.12952413\n",
      "  0.12275454]\n",
      "train_accuracy: 0.5309779825908858\n",
      "============== 2400 =================\n",
      "alpha: [-0.0867989  -0.12222629 -0.00833944 ...  0.13468758  0.13166136\n",
      "  0.12260219]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 2500 =================\n",
      "alpha: [-0.09484715 -0.12559086 -0.00805461 ...  0.13100048  0.12860358\n",
      "  0.12224291]\n",
      "train_accuracy: 0.5412186379928315\n",
      "============== 2600 =================\n",
      "alpha: [-0.09446596 -0.12358154 -0.01145075 ...  0.12937371  0.13067878\n",
      "  0.12075267]\n",
      "train_accuracy: 0.5371223758320532\n",
      "============== 2700 =================\n",
      "alpha: [-0.09292228 -0.12464508 -0.01181718 ...  0.12963987  0.13518065\n",
      "  0.12388969]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 2800 =================\n",
      "alpha: [-0.09185398 -0.12124761 -0.01255829 ...  0.12715401  0.13705486\n",
      "  0.12642702]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 2900 =================\n",
      "alpha: [-0.092229   -0.12448668 -0.01285404 ...  0.12751868  0.13885306\n",
      "  0.1261142 ]\n",
      "train_accuracy: 0.543778801843318\n",
      "============== 3000 =================\n",
      "alpha: [-0.0889208  -0.12723962 -0.01620006 ...  0.12885156  0.13261932\n",
      "  0.12645034]\n",
      "train_accuracy: 0.5314900153609831\n",
      "============== 3100 =================\n",
      "alpha: [-0.09003983 -0.12650754 -0.01738833 ...  0.12770281  0.13134207\n",
      "  0.12808805]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 3200 =================\n",
      "alpha: [-0.09007879 -0.12563456 -0.01789209 ...  0.12552403  0.13467155\n",
      "  0.1273761 ]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 3300 =================\n",
      "alpha: [-0.0929831  -0.12639707 -0.01641146 ...  0.12342526  0.1290751\n",
      "  0.12802015]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 3400 =================\n",
      "alpha: [-0.09197356 -0.12988765 -0.01507929 ...  0.12176235  0.12930561\n",
      "  0.12412094]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 3500 =================\n",
      "alpha: [-0.09570651 -0.12735463 -0.01354271 ...  0.11664183  0.13753474\n",
      "  0.12322214]\n",
      "train_accuracy: 0.5376344086021505\n",
      "============== 3600 =================\n",
      "alpha: [-0.0914995  -0.12882603 -0.01201506 ...  0.11620869  0.13796394\n",
      "  0.12055909]\n",
      "train_accuracy: 0.5371223758320532\n",
      "============== 3700 =================\n",
      "alpha: [-0.09287852 -0.13119974 -0.01164982 ...  0.11406274  0.13863192\n",
      "  0.12475372]\n",
      "train_accuracy: 0.5345622119815668\n",
      "============== 3800 =================\n",
      "alpha: [-0.08797195 -0.13103359 -0.01358581 ...  0.1213278   0.13254975\n",
      "  0.12170829]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 3900 =================\n",
      "alpha: [-0.09142891 -0.13266984 -0.0131375  ...  0.12490297  0.12906254\n",
      "  0.12499888]\n",
      "train_accuracy: 0.5345622119815668\n",
      "============== 4000 =================\n",
      "alpha: [-0.09198339 -0.12754344 -0.0117678  ...  0.11968302  0.12722673\n",
      "  0.12761833]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 4100 =================\n",
      "alpha: [-0.09597604 -0.12918614 -0.00987646 ...  0.12297341  0.12682136\n",
      "  0.13136186]\n",
      "train_accuracy: 0.5376344086021505\n",
      "============== 4200 =================\n",
      "alpha: [-0.09908051 -0.13124597 -0.00919807 ...  0.12131782  0.13010859\n",
      "  0.13001579]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 4300 =================\n",
      "alpha: [-0.09306858 -0.13084531 -0.00972055 ...  0.12293284  0.12901232\n",
      "  0.1266414 ]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 4400 =================\n",
      "alpha: [-0.09539604 -0.13042496 -0.01243011 ...  0.12505681  0.1322321\n",
      "  0.13634549]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 4500 =================\n",
      "alpha: [-0.09840716 -0.13665484 -0.01123556 ...  0.1200654   0.13320257\n",
      "  0.12968398]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 4600 =================\n",
      "alpha: [-0.098828   -0.13357073 -0.00935534 ...  0.12002101  0.13248154\n",
      "  0.131568  ]\n",
      "train_accuracy: 0.5371223758320532\n",
      "============== 4700 =================\n",
      "alpha: [-0.09930548 -0.13289451 -0.01143633 ...  0.12160998  0.13304937\n",
      "  0.13364783]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 4800 =================\n",
      "alpha: [-0.10206482 -0.13022607 -0.01109558 ...  0.11956386  0.13897536\n",
      "  0.1306062 ]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 4900 =================\n",
      "alpha: [-0.10045632 -0.12464379 -0.01525363 ...  0.12059275  0.13467991\n",
      "  0.12918976]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 5000 =================\n",
      "alpha: [-0.10844085 -0.12204208 -0.01572375 ...  0.12473843  0.13090804\n",
      "  0.12510793]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 5100 =================\n",
      "alpha: [-0.1096472  -0.12614783 -0.01499898 ...  0.12313576  0.13142858\n",
      "  0.12991168]\n",
      "train_accuracy: 0.5355862775217614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== 5200 =================\n",
      "alpha: [-0.10253423 -0.12938155 -0.0138437  ...  0.12609943  0.12652153\n",
      "  0.12727076]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 5300 =================\n",
      "alpha: [-0.10089706 -0.12493997 -0.01307299 ...  0.12583842  0.12372472\n",
      "  0.124781  ]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 5400 =================\n",
      "alpha: [-0.10782701 -0.12424716 -0.01406561 ...  0.12300266  0.12632963\n",
      "  0.12295534]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 5500 =================\n",
      "alpha: [-0.11048977 -0.12545961 -0.01327533 ...  0.12139624  0.12711176\n",
      "  0.12308882]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 5600 =================\n",
      "alpha: [-0.11418101 -0.12462369 -0.01394955 ...  0.11857926  0.13120349\n",
      "  0.13151393]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 5700 =================\n",
      "alpha: [-0.11082922 -0.12184925 -0.01448748 ...  0.12795911  0.12924247\n",
      "  0.12841681]\n",
      "train_accuracy: 0.540194572452637\n",
      "============== 5800 =================\n",
      "alpha: [-0.10322647 -0.12695306 -0.01530629 ...  0.13481438  0.13017189\n",
      "  0.13134367]\n",
      "train_accuracy: 0.5345622119815668\n",
      "============== 5900 =================\n",
      "alpha: [-0.1028038  -0.13241424 -0.01716648 ...  0.12837321  0.13288658\n",
      "  0.13221835]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 6000 =================\n",
      "alpha: [-0.10575285 -0.12861506 -0.02076117 ...  0.1316272   0.130626\n",
      "  0.12988886]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 6100 =================\n",
      "alpha: [-0.10248912 -0.12810062 -0.02264836 ...  0.12684326  0.13139768\n",
      "  0.1267891 ]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 6200 =================\n",
      "alpha: [-0.09834912 -0.13401421 -0.01925428 ...  0.12184993  0.13107782\n",
      "  0.12607618]\n",
      "train_accuracy: 0.5427547363031234\n",
      "============== 6300 =================\n",
      "alpha: [-0.09463    -0.12975861 -0.01899895 ...  0.12434901  0.13079635\n",
      "  0.12814884]\n",
      "train_accuracy: 0.543778801843318\n",
      "============== 6400 =================\n",
      "alpha: [-0.0880152  -0.12462014 -0.02032703 ...  0.12052913  0.13193658\n",
      "  0.13228459]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 6500 =================\n",
      "alpha: [-0.09045726 -0.12323073 -0.01664367 ...  0.11867929  0.12976424\n",
      "  0.12897256]\n",
      "train_accuracy: 0.5376344086021505\n",
      "============== 6600 =================\n",
      "alpha: [-0.09505192 -0.12455315 -0.01728847 ...  0.11509795  0.1319707\n",
      "  0.1292215 ]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 6700 =================\n",
      "alpha: [-0.0947834  -0.12298282 -0.01499937 ...  0.12384096  0.1304709\n",
      "  0.13418817]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 6800 =================\n",
      "alpha: [-0.09332067 -0.12279727 -0.01644772 ...  0.12575391  0.13429082\n",
      "  0.13687533]\n",
      "train_accuracy: 0.540194572452637\n",
      "============== 6900 =================\n",
      "alpha: [-0.08542528 -0.12602542 -0.01538786 ...  0.13072296  0.12959719\n",
      "  0.13724795]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 7000 =================\n",
      "alpha: [-0.08699358 -0.12317492 -0.02017803 ...  0.12869569  0.12600954\n",
      "  0.13136026]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 7100 =================\n",
      "alpha: [-0.08918143 -0.12085289 -0.01957846 ...  0.12801134  0.12518162\n",
      "  0.12761538]\n",
      "train_accuracy: 0.5345622119815668\n",
      "============== 7200 =================\n",
      "alpha: [-0.09724845 -0.12078183 -0.0196933  ...  0.12755429  0.12699436\n",
      "  0.12683836]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 7300 =================\n",
      "alpha: [-0.09030287 -0.12078491 -0.0179957  ...  0.12698663  0.12722435\n",
      "  0.13093608]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 7400 =================\n",
      "alpha: [-0.08515758 -0.12263735 -0.01617554 ...  0.12457199  0.12229372\n",
      "  0.12449607]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 7500 =================\n",
      "alpha: [-0.08825004 -0.12254179 -0.01625032 ...  0.13257444  0.13299978\n",
      "  0.11982582]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 7600 =================\n",
      "alpha: [-0.0903925  -0.12306469 -0.01451878 ...  0.13034281  0.12989618\n",
      "  0.11878567]\n",
      "train_accuracy: 0.5376344086021505\n",
      "============== 7700 =================\n",
      "alpha: [-0.08646247 -0.11979879 -0.01439965 ...  0.12840326  0.12806703\n",
      "  0.11981165]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 7800 =================\n",
      "alpha: [-0.08476777 -0.12045894 -0.01515571 ...  0.12774494  0.13004937\n",
      "  0.12444125]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 7900 =================\n",
      "alpha: [-0.08518893 -0.11405172 -0.01619258 ...  0.11835647  0.12724136\n",
      "  0.1255453 ]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 8000 =================\n",
      "alpha: [-0.09099847 -0.11872776 -0.01968777 ...  0.11776345  0.13311122\n",
      "  0.12815573]\n",
      "train_accuracy: 0.540194572452637\n",
      "============== 8100 =================\n",
      "alpha: [-0.09228238 -0.11900227 -0.01795656 ...  0.12114954  0.13265529\n",
      "  0.12559924]\n",
      "train_accuracy: 0.5412186379928315\n",
      "============== 8200 =================\n",
      "alpha: [-0.0937242  -0.12262189 -0.01708034 ...  0.12174991  0.13117372\n",
      "  0.13298984]\n",
      "train_accuracy: 0.540194572452637\n",
      "============== 8300 =================\n",
      "alpha: [-0.10084865 -0.125704   -0.01522917 ...  0.12218514  0.12844449\n",
      "  0.13245081]\n",
      "train_accuracy: 0.5314900153609831\n",
      "============== 8400 =================\n",
      "alpha: [-0.09813922 -0.1223117  -0.01399632 ...  0.12050772  0.12880139\n",
      "  0.13283926]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 8500 =================\n",
      "alpha: [-0.09971515 -0.12511779 -0.01145968 ...  0.12758938  0.12799283\n",
      "  0.13969586]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 8600 =================\n",
      "alpha: [-0.10198385 -0.12342154 -0.01015819 ...  0.12456259  0.13301331\n",
      "  0.14063616]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 8700 =================\n",
      "alpha: [-0.10411282 -0.12373991 -0.00835293 ...  0.12379103  0.13502491\n",
      "  0.13246118]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 8800 =================\n",
      "alpha: [-0.10350562 -0.12202119 -0.00686377 ...  0.1213004   0.1329074\n",
      "  0.13316601]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 8900 =================\n",
      "alpha: [-0.11109501 -0.12803792 -0.00715879 ...  0.1203638   0.13429798\n",
      "  0.13161555]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 9000 =================\n",
      "alpha: [-0.11561498 -0.12658894 -0.0067822  ...  0.11556245  0.13417638\n",
      "  0.13427094]\n",
      "train_accuracy: 0.5279057859703021\n",
      "============== 9100 =================\n",
      "alpha: [-0.11176663 -0.12801885 -0.00894052 ...  0.11706553  0.13274926\n",
      "  0.13451886]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 9200 =================\n",
      "alpha: [-0.11058588 -0.12924867 -0.01089406 ...  0.11869127  0.12767415\n",
      "  0.12826626]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 9300 =================\n",
      "alpha: [-0.10678275 -0.13387364 -0.01008316 ...  0.11860536  0.12808642\n",
      "  0.12637798]\n",
      "train_accuracy: 0.5376344086021505\n",
      "============== 9400 =================\n",
      "alpha: [-0.11171841 -0.13113513 -0.01076262 ...  0.12415625  0.12264166\n",
      "  0.11937099]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 9500 =================\n",
      "alpha: [-0.11149423 -0.13284064 -0.01312458 ...  0.12400303  0.1202189\n",
      "  0.12018466]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 9600 =================\n",
      "alpha: [-0.10732033 -0.12967477 -0.01505773 ...  0.12690215  0.12355945\n",
      "  0.11297125]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 9700 =================\n",
      "alpha: [-0.10681568 -0.12893326 -0.01561978 ...  0.12506466  0.11960749\n",
      "  0.11595779]\n",
      "train_accuracy: 0.5345622119815668\n",
      "============== 9800 =================\n",
      "alpha: [-0.10572779 -0.12815926 -0.01777593 ...  0.12040365  0.12427386\n",
      "  0.11828343]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 9900 =================\n",
      "alpha: [-0.09773087 -0.12861319 -0.01562889 ...  0.11485475  0.123441\n",
      "  0.12345932]\n",
      "train_accuracy: 0.5314900153609831\n",
      "============== 10000 =================\n",
      "alpha: [-0.09026679 -0.12489108 -0.01382675 ...  0.11940901  0.12745229\n",
      "  0.12266302]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 10100 =================\n",
      "alpha: [-0.09303476 -0.1205293  -0.0141501  ...  0.11766884  0.12962921\n",
      "  0.12946592]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 10200 =================\n",
      "alpha: [-0.09614657 -0.12326326 -0.01315672 ...  0.12102183  0.13062007\n",
      "  0.12838768]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 10300 =================\n",
      "alpha: [-0.09851406 -0.12517397 -0.01170734 ...  0.12457204  0.13485663\n",
      "  0.12700921]\n",
      "train_accuracy: 0.5340501792114696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== 10400 =================\n",
      "alpha: [-0.09955536 -0.12695932 -0.01129969 ...  0.12229618  0.13019712\n",
      "  0.12967542]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 10500 =================\n",
      "alpha: [-0.09939014 -0.13008089 -0.01058151 ...  0.12575908  0.13295767\n",
      "  0.12427578]\n",
      "train_accuracy: 0.5376344086021505\n",
      "============== 10600 =================\n",
      "alpha: [-0.09734709 -0.12561864 -0.01189215 ...  0.1264432   0.13170669\n",
      "  0.12715984]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 10700 =================\n",
      "alpha: [-0.09862133 -0.12374726 -0.01012151 ...  0.12541717  0.12475082\n",
      "  0.12320029]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 10800 =================\n",
      "alpha: [-0.09391478 -0.12105324 -0.01104982 ...  0.12886057  0.12469652\n",
      "  0.12831274]\n",
      "train_accuracy: 0.5309779825908858\n",
      "============== 10900 =================\n",
      "alpha: [-0.09141415 -0.11913174 -0.01067706 ...  0.13007841  0.12560884\n",
      "  0.12660903]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 11000 =================\n",
      "alpha: [-0.08957041 -0.12124046 -0.00874189 ...  0.12711286  0.1235955\n",
      "  0.12644173]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 11100 =================\n",
      "alpha: [-0.0867209  -0.12333795 -0.00797058 ...  0.12866282  0.12810272\n",
      "  0.12988625]\n",
      "train_accuracy: 0.5314900153609831\n",
      "============== 11200 =================\n",
      "alpha: [-0.08557327 -0.1253814  -0.00910292 ...  0.125291    0.12812179\n",
      "  0.12885059]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 11300 =================\n",
      "alpha: [-0.08472801 -0.13009614 -0.01274747 ...  0.12268142  0.13107692\n",
      "  0.13178931]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 11400 =================\n",
      "alpha: [-0.08335945 -0.13373669 -0.01781208 ...  0.12291898  0.13546632\n",
      "  0.13518457]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 11500 =================\n",
      "alpha: [-0.0801694  -0.13130188 -0.02113379 ...  0.12256614  0.13365251\n",
      "  0.13134477]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 11600 =================\n",
      "alpha: [-0.08155999 -0.13120892 -0.02074039 ...  0.12728143  0.13218982\n",
      "  0.13024127]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 11700 =================\n",
      "alpha: [-0.08177952 -0.13073701 -0.02073417 ...  0.12857711  0.13706342\n",
      "  0.13133499]\n",
      "train_accuracy: 0.5279057859703021\n",
      "============== 11800 =================\n",
      "alpha: [-0.08687119 -0.12698217 -0.02456576 ...  0.13140653  0.14463623\n",
      "  0.13290229]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 11900 =================\n",
      "alpha: [-0.09202534 -0.12669873 -0.0238125  ...  0.13109367  0.13820505\n",
      "  0.12395962]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 12000 =================\n",
      "alpha: [-0.09440829 -0.12720973 -0.02540522 ...  0.1291345   0.13856114\n",
      "  0.12485608]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 12100 =================\n",
      "alpha: [-0.09415783 -0.13119114 -0.02991031 ...  0.12555058  0.13436706\n",
      "  0.12237046]\n",
      "train_accuracy: 0.5314900153609831\n",
      "============== 12200 =================\n",
      "alpha: [-0.0964652  -0.13778479 -0.02890642 ...  0.12750715  0.13784098\n",
      "  0.1199847 ]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 12300 =================\n",
      "alpha: [-0.0983588  -0.13443035 -0.02420025 ...  0.13305496  0.13512199\n",
      "  0.11986515]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 12400 =================\n",
      "alpha: [-0.09791389 -0.13357309 -0.02368704 ...  0.13153718  0.13769403\n",
      "  0.12085148]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 12500 =================\n",
      "alpha: [-0.09675728 -0.13286942 -0.0227481  ...  0.12978719  0.13264545\n",
      "  0.12033635]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 12600 =================\n",
      "alpha: [-0.09517736 -0.13984444 -0.01868111 ...  0.13345231  0.13049417\n",
      "  0.12177395]\n",
      "train_accuracy: 0.5314900153609831\n",
      "============== 12700 =================\n",
      "alpha: [-0.09309822 -0.13660875 -0.01730008 ...  0.13356605  0.13695019\n",
      "  0.1229535 ]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 12800 =================\n",
      "alpha: [-0.09750345 -0.13808383 -0.02167913 ...  0.13111089  0.13318487\n",
      "  0.12060853]\n",
      "train_accuracy: 0.5422427035330261\n",
      "============== 12900 =================\n",
      "alpha: [-0.1016597  -0.13227369 -0.01934792 ...  0.12812422  0.12953866\n",
      "  0.12026589]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 13000 =================\n",
      "alpha: [-0.09758759 -0.1316866  -0.01758848 ...  0.12287284  0.13047282\n",
      "  0.12110691]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 13100 =================\n",
      "alpha: [-0.0963971  -0.13334251 -0.01799725 ...  0.12569698  0.12938034\n",
      "  0.12188562]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 13200 =================\n",
      "alpha: [-0.09437119 -0.13056373 -0.01786096 ...  0.12028345  0.12863855\n",
      "  0.12521968]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 13300 =================\n",
      "alpha: [-0.09398603 -0.12939456 -0.01625588 ...  0.12189807  0.13301382\n",
      "  0.12517917]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 13400 =================\n",
      "alpha: [-0.09918901 -0.12745037 -0.01484811 ...  0.12606947  0.13272001\n",
      "  0.12740824]\n",
      "train_accuracy: 0.5442908346134152\n",
      "============== 13500 =================\n",
      "alpha: [-0.09617163 -0.12396951 -0.01429968 ...  0.12212443  0.1333413\n",
      "  0.12154422]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 13600 =================\n",
      "alpha: [-0.09279834 -0.12137787 -0.01254793 ...  0.12014298  0.13734996\n",
      "  0.12045626]\n",
      "train_accuracy: 0.5314900153609831\n",
      "============== 13700 =================\n",
      "alpha: [-0.09056606 -0.11809088 -0.01217759 ...  0.12097363  0.13162721\n",
      "  0.11574541]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 13800 =================\n",
      "alpha: [-0.09270816 -0.11652016 -0.00997369 ...  0.11976712  0.12504968\n",
      "  0.12186446]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 13900 =================\n",
      "alpha: [-0.09960312 -0.11684491 -0.00822033 ...  0.12634305  0.12873151\n",
      "  0.11848391]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 14000 =================\n",
      "alpha: [-0.1006559  -0.11761035 -0.00701186 ...  0.12501127  0.12165741\n",
      "  0.11732852]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 14100 =================\n",
      "alpha: [-0.10574958 -0.11903145 -0.00575719 ...  0.12498116  0.12126778\n",
      "  0.11757206]\n",
      "train_accuracy: 0.5371223758320532\n",
      "============== 14200 =================\n",
      "alpha: [-0.10598474 -0.1192916  -0.00548023 ...  0.12135433  0.12103365\n",
      "  0.12092852]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 14300 =================\n",
      "alpha: [-0.10201054 -0.12554755 -0.00509634 ...  0.12248881  0.12444435\n",
      "  0.12421802]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 14400 =================\n",
      "alpha: [-0.10048362 -0.13104271 -0.00920189 ...  0.12654808  0.12719837\n",
      "  0.12260906]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 14500 =================\n",
      "alpha: [-0.09900272 -0.12345648 -0.00759239 ...  0.1243244   0.13114204\n",
      "  0.12412257]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 14600 =================\n",
      "alpha: [-0.10113647 -0.12017634 -0.01375318 ...  0.12804633  0.13629599\n",
      "  0.12320827]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 14700 =================\n",
      "alpha: [-0.09786535 -0.11739827 -0.01193238 ...  0.12470846  0.13872132\n",
      "  0.12093327]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 14800 =================\n",
      "alpha: [-0.10111814 -0.12093106 -0.01505482 ...  0.12118098  0.13396452\n",
      "  0.12352357]\n",
      "train_accuracy: 0.5376344086021505\n",
      "============== 14900 =================\n",
      "alpha: [-0.09973452 -0.12289172 -0.01843142 ...  0.12455657  0.13051566\n",
      "  0.11911699]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 15000 =================\n",
      "alpha: [-0.1034291  -0.11867072 -0.01847669 ...  0.1261056   0.129677\n",
      "  0.11410662]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 15100 =================\n",
      "alpha: [-0.10435516 -0.12507097 -0.01774088 ...  0.12407326  0.129007\n",
      "  0.11611913]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 15200 =================\n",
      "alpha: [-0.10246406 -0.12521613 -0.0186725  ...  0.12328725  0.12539968\n",
      "  0.12300617]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 15300 =================\n",
      "alpha: [-0.10876693 -0.12373003 -0.02302309 ...  0.12459939  0.12719322\n",
      "  0.12592917]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 15400 =================\n",
      "alpha: [-0.10946173 -0.12401753 -0.02494271 ...  0.12187979  0.12411167\n",
      "  0.12648977]\n",
      "train_accuracy: 0.5412186379928315\n",
      "============== 15500 =================\n",
      "alpha: [-0.10215897 -0.12616565 -0.02190324 ...  0.12086645  0.13137387\n",
      "  0.1277084 ]\n",
      "train_accuracy: 0.5350742447516641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== 15600 =================\n",
      "alpha: [-0.10898789 -0.12042671 -0.01908792 ...  0.12343904  0.12850635\n",
      "  0.12163205]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 15700 =================\n",
      "alpha: [-0.10456394 -0.1211214  -0.01643863 ...  0.12181669  0.12921355\n",
      "  0.11655786]\n",
      "train_accuracy: 0.5314900153609831\n",
      "============== 15800 =================\n",
      "alpha: [-0.10626083 -0.12182112 -0.01530653 ...  0.12044623  0.13199186\n",
      "  0.11907207]\n",
      "train_accuracy: 0.5442908346134152\n",
      "============== 15900 =================\n",
      "alpha: [-0.10927629 -0.1272854  -0.01333344 ...  0.12561222  0.12744388\n",
      "  0.12023341]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 16000 =================\n",
      "alpha: [-0.10360264 -0.1298948  -0.01753026 ...  0.12267718  0.12642235\n",
      "  0.12330488]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 16100 =================\n",
      "alpha: [-0.10555836 -0.12935124 -0.01705761 ...  0.12430114  0.12883138\n",
      "  0.1209591 ]\n",
      "train_accuracy: 0.5407066052227343\n",
      "============== 16200 =================\n",
      "alpha: [-0.10359589 -0.12844891 -0.01599506 ...  0.12276366  0.12988732\n",
      "  0.12059924]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 16300 =================\n",
      "alpha: [-0.10871727 -0.12912343 -0.0140841  ...  0.12245966  0.13199165\n",
      "  0.12117141]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 16400 =================\n",
      "alpha: [-0.1066361  -0.12965014 -0.01287294 ...  0.12276617  0.12768059\n",
      "  0.1165088 ]\n",
      "train_accuracy: 0.5314900153609831\n",
      "============== 16500 =================\n",
      "alpha: [-0.1032557  -0.12638647 -0.01460946 ...  0.12330095  0.12740894\n",
      "  0.1200845 ]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 16600 =================\n",
      "alpha: [-0.10505315 -0.12532769 -0.01276147 ...  0.11991276  0.12984067\n",
      "  0.12254837]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 16700 =================\n",
      "alpha: [-0.10128782 -0.13066199 -0.01146359 ...  0.1191641   0.13019234\n",
      "  0.124863  ]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 16800 =================\n",
      "alpha: [-0.10034371 -0.1275841  -0.01298661 ...  0.11869933  0.1265618\n",
      "  0.12635351]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 16900 =================\n",
      "alpha: [-0.10040558 -0.13328162 -0.01536434 ...  0.1217718   0.12770939\n",
      "  0.12267642]\n",
      "train_accuracy: 0.5417306707629288\n",
      "============== 17000 =================\n",
      "alpha: [-0.10427383 -0.13431123 -0.01521379 ...  0.11689047  0.12976166\n",
      "  0.11915723]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 17100 =================\n",
      "alpha: [-0.10311691 -0.13729784 -0.01424481 ...  0.12372368  0.13158222\n",
      "  0.12492777]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 17200 =================\n",
      "alpha: [-0.10575369 -0.13866206 -0.01243698 ...  0.125534    0.13156691\n",
      "  0.12851624]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 17300 =================\n",
      "alpha: [-0.10431283 -0.13803677 -0.01531564 ...  0.12347951  0.12591281\n",
      "  0.13066226]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 17400 =================\n",
      "alpha: [-0.10752509 -0.13774207 -0.01435861 ...  0.12819371  0.12911436\n",
      "  0.13062183]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 17500 =================\n",
      "alpha: [-0.10839784 -0.13915354 -0.01508412 ...  0.12388625  0.13032777\n",
      "  0.13303525]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 17600 =================\n",
      "alpha: [-0.10837617 -0.13580636 -0.01612964 ...  0.12394936  0.12936159\n",
      "  0.13794435]\n",
      "train_accuracy: 0.5345622119815668\n",
      "============== 17700 =================\n",
      "alpha: [-0.10463439 -0.13111819 -0.013524   ...  0.12130945  0.12564778\n",
      "  0.13736198]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 17800 =================\n",
      "alpha: [-0.10454016 -0.13143464 -0.0126593  ...  0.12354801  0.12932821\n",
      "  0.13580114]\n",
      "train_accuracy: 0.5407066052227343\n",
      "============== 17900 =================\n",
      "alpha: [-0.106292   -0.12492167 -0.01275802 ...  0.12541553  0.13043149\n",
      "  0.12844982]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 18000 =================\n",
      "alpha: [-0.11329432 -0.12764881 -0.01114712 ...  0.12563508  0.13064393\n",
      "  0.12851034]\n",
      "train_accuracy: 0.5371223758320532\n",
      "============== 18100 =================\n",
      "alpha: [-0.11088352 -0.12530349 -0.01017906 ...  0.12574503  0.13055917\n",
      "  0.13118024]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 18200 =================\n",
      "alpha: [-0.10373767 -0.13245581 -0.00836692 ...  0.12444687  0.13511283\n",
      "  0.12860533]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 18300 =================\n",
      "alpha: [-0.11065233 -0.13396913 -0.00909181 ...  0.12236525  0.13509133\n",
      "  0.1306388 ]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 18400 =================\n",
      "alpha: [-0.11006021 -0.13153262 -0.00884454 ...  0.12455577  0.13319746\n",
      "  0.12979418]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 18500 =================\n",
      "alpha: [-0.11097869 -0.13373255 -0.00814109 ...  0.12912511  0.13055918\n",
      "  0.13407423]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 18600 =================\n",
      "alpha: [-0.11206241 -0.12933717 -0.00689614 ...  0.12815128  0.13591971\n",
      "  0.13157965]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 18700 =================\n",
      "alpha: [-0.10908563 -0.13320365 -0.00564828 ...  0.12490985  0.13478058\n",
      "  0.13034763]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 18800 =================\n",
      "alpha: [-0.10901873 -0.13079516 -0.00502538 ...  0.12028794  0.13229746\n",
      "  0.12847549]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 18900 =================\n",
      "alpha: [-0.10802319 -0.13124816 -0.00416848 ...  0.12949211  0.13440571\n",
      "  0.12595923]\n",
      "train_accuracy: 0.5432667690732207\n",
      "============== 19000 =================\n",
      "alpha: [-0.10561884 -0.12849365 -0.00372555 ...  0.13397054  0.13461678\n",
      "  0.12545344]\n",
      "train_accuracy: 0.5422427035330261\n",
      "============== 19100 =================\n",
      "alpha: [-0.10087887 -0.13228949 -0.00357468 ...  0.12685405  0.13712961\n",
      "  0.1190626 ]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 19200 =================\n",
      "alpha: [-0.10194688 -0.12656641 -0.00758853 ...  0.12967434  0.14200401\n",
      "  0.12837499]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 19300 =================\n",
      "alpha: [-0.10162085 -0.12455272 -0.01107921 ...  0.13437084  0.13785821\n",
      "  0.13516882]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 19400 =================\n",
      "alpha: [-0.09437528 -0.12565765 -0.01657929 ...  0.13599707  0.13367828\n",
      "  0.13458055]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 19500 =================\n",
      "alpha: [-0.09693545 -0.13073996 -0.01737769 ...  0.13504761  0.12928217\n",
      "  0.14265449]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 19600 =================\n",
      "alpha: [-0.09725631 -0.13279242 -0.01817879 ...  0.1304866   0.13119335\n",
      "  0.13942387]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 19700 =================\n",
      "alpha: [-0.09835369 -0.13413733 -0.01819118 ...  0.13073556  0.13055872\n",
      "  0.12857119]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 19800 =================\n",
      "alpha: [-0.0992477  -0.13244222 -0.01872752 ...  0.12975141  0.13076127\n",
      "  0.13495539]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 19900 =================\n",
      "alpha: [-0.09671985 -0.13655937 -0.02233668 ...  0.12705269  0.12614232\n",
      "  0.13708179]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 20000 =================\n",
      "alpha: [-0.09825136 -0.12697691 -0.02410217 ...  0.12645888  0.1287902\n",
      "  0.13585971]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 20100 =================\n",
      "alpha: [-0.10109749 -0.13119303 -0.02154029 ...  0.12875674  0.12528258\n",
      "  0.1336717 ]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 20200 =================\n",
      "alpha: [-0.09669837 -0.13165756 -0.02298894 ...  0.1260198   0.13171276\n",
      "  0.13729393]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 20300 =================\n",
      "alpha: [-0.09402395 -0.13526114 -0.02415136 ...  0.12929164  0.12156322\n",
      "  0.14319514]\n",
      "train_accuracy: 0.5284178187403994\n",
      "============== 20400 =================\n",
      "alpha: [-0.10201159 -0.13249526 -0.02288576 ...  0.12850511  0.12231581\n",
      "  0.14155596]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 20500 =================\n",
      "alpha: [-0.10158493 -0.13199451 -0.02245592 ...  0.13298144  0.12643298\n",
      "  0.14124597]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 20600 =================\n",
      "alpha: [-0.09740922 -0.13505743 -0.02426739 ...  0.13784469  0.13007152\n",
      "  0.14291988]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 20700 =================\n",
      "alpha: [-0.09435642 -0.12612245 -0.02326923 ...  0.13979424  0.12832949\n",
      "  0.13705785]\n",
      "train_accuracy: 0.5350742447516641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== 20800 =================\n",
      "alpha: [-0.09026024 -0.12964952 -0.02258646 ...  0.13703475  0.13315284\n",
      "  0.1338966 ]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 20900 =================\n",
      "alpha: [-0.09124538 -0.12881176 -0.02034472 ...  0.13471277  0.12603086\n",
      "  0.12959058]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 21000 =================\n",
      "alpha: [-0.09330101 -0.1301107  -0.01762704 ...  0.13106964  0.12452202\n",
      "  0.12837664]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 21100 =================\n",
      "alpha: [-0.09156049 -0.13371182 -0.01605198 ...  0.13112297  0.12454831\n",
      "  0.12700951]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 21200 =================\n",
      "alpha: [-0.09393745 -0.129206   -0.01604924 ...  0.13064973  0.1267329\n",
      "  0.12568493]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 21300 =================\n",
      "alpha: [-0.09303855 -0.13405934 -0.01423931 ...  0.12694736  0.12155197\n",
      "  0.12484883]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 21400 =================\n",
      "alpha: [-0.0929881  -0.14169017 -0.01334946 ...  0.12752421  0.11927139\n",
      "  0.12686666]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 21500 =================\n",
      "alpha: [-0.09578618 -0.13862856 -0.01366847 ...  0.13005241  0.11675105\n",
      "  0.12341326]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 21600 =================\n",
      "alpha: [-0.0943848  -0.13809793 -0.01267912 ...  0.13292456  0.11719266\n",
      "  0.12229189]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 21700 =================\n",
      "alpha: [-0.09622048 -0.13414477 -0.0153502  ...  0.13504833  0.11787638\n",
      "  0.11923415]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 21800 =================\n",
      "alpha: [-0.09275517 -0.13340611 -0.01563137 ...  0.13572493  0.12187297\n",
      "  0.12204658]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 21900 =================\n",
      "alpha: [-0.09378389 -0.13207578 -0.01508034 ...  0.12836805  0.12131298\n",
      "  0.11996869]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 22000 =================\n",
      "alpha: [-0.09019669 -0.13468356 -0.01277338 ...  0.13103671  0.12856448\n",
      "  0.11912803]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 22100 =================\n",
      "alpha: [-0.09146372 -0.13535178 -0.0158719  ...  0.13922318  0.13041848\n",
      "  0.117458  ]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 22200 =================\n",
      "alpha: [-0.09801069 -0.14011649 -0.01852589 ...  0.13597473  0.12737853\n",
      "  0.12241237]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 22300 =================\n",
      "alpha: [-0.09905367 -0.13515986 -0.01779309 ...  0.13720258  0.12676621\n",
      "  0.12372371]\n",
      "train_accuracy: 0.5314900153609831\n",
      "============== 22400 =================\n",
      "alpha: [-0.10049747 -0.13084139 -0.01610424 ...  0.1367982   0.12539863\n",
      "  0.12561969]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 22500 =================\n",
      "alpha: [-0.10005466 -0.13438641 -0.01463512 ...  0.13527386  0.12355146\n",
      "  0.12449124]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 22600 =================\n",
      "alpha: [-0.09489531 -0.12922051 -0.01554409 ...  0.1343718   0.12118757\n",
      "  0.12354278]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 22700 =================\n",
      "alpha: [-0.09439417 -0.12846928 -0.01537437 ...  0.13358936  0.11808597\n",
      "  0.12980711]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 22800 =================\n",
      "alpha: [-0.09315175 -0.1298301  -0.0146293  ...  0.13364004  0.11747535\n",
      "  0.12904603]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 22900 =================\n",
      "alpha: [-0.09760882 -0.12898574 -0.01507722 ...  0.13744215  0.12231035\n",
      "  0.12832111]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 23000 =================\n",
      "alpha: [-0.09901546 -0.13106375 -0.01544955 ...  0.13253335  0.12569317\n",
      "  0.12326895]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 23100 =================\n",
      "alpha: [-0.10299109 -0.13196383 -0.01667778 ...  0.1320415   0.12836966\n",
      "  0.11710908]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 23200 =================\n",
      "alpha: [-0.10006429 -0.13445484 -0.01493096 ...  0.13377367  0.13221265\n",
      "  0.11859508]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 23300 =================\n",
      "alpha: [-0.10201094 -0.13571576 -0.01352382 ...  0.13370357  0.13614919\n",
      "  0.12236203]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 23400 =================\n",
      "alpha: [-0.0978517  -0.13095932 -0.01524079 ...  0.13290715  0.13228984\n",
      "  0.12268846]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 23500 =================\n",
      "alpha: [-0.09904831 -0.12571868 -0.02289509 ...  0.13355141  0.13158724\n",
      "  0.12201742]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 23600 =================\n",
      "alpha: [-0.10378238 -0.12301838 -0.02230423 ...  0.13491101  0.13214038\n",
      "  0.1260256 ]\n",
      "train_accuracy: 0.5345622119815668\n",
      "============== 23700 =================\n",
      "alpha: [-0.10058636 -0.12871721 -0.02150927 ...  0.13408834  0.1323609\n",
      "  0.12770344]\n",
      "train_accuracy: 0.5407066052227343\n",
      "============== 23800 =================\n",
      "alpha: [-0.0965172  -0.1341639  -0.02055533 ...  0.13151882  0.12906161\n",
      "  0.12810712]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 23900 =================\n",
      "alpha: [-0.0958898  -0.13504846 -0.01767487 ...  0.13104867  0.12643849\n",
      "  0.12792408]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 24000 =================\n",
      "alpha: [-0.09345206 -0.13628784 -0.01682277 ...  0.12540652  0.1260205\n",
      "  0.13023694]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 24100 =================\n",
      "alpha: [-0.08760768 -0.13356735 -0.01451838 ...  0.12637379  0.12302563\n",
      "  0.13649762]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 24200 =================\n",
      "alpha: [-0.09112964 -0.1358654  -0.01194012 ...  0.12244495  0.1189132\n",
      "  0.1399036 ]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 24300 =================\n",
      "alpha: [-0.09552306 -0.12930991 -0.01223125 ...  0.12750574  0.11989908\n",
      "  0.13795498]\n",
      "train_accuracy: 0.5412186379928315\n",
      "============== 24400 =================\n",
      "alpha: [-0.09463538 -0.12919213 -0.01109446 ...  0.12545225  0.12354378\n",
      "  0.13571203]\n",
      "train_accuracy: 0.5371223758320532\n",
      "============== 24500 =================\n",
      "alpha: [-0.0998767  -0.12933048 -0.00925695 ...  0.13069975  0.12014582\n",
      "  0.13267869]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 24600 =================\n",
      "alpha: [-0.10032352 -0.12313983 -0.00800183 ...  0.12606059  0.12269505\n",
      "  0.13434834]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 24700 =================\n",
      "alpha: [-0.10206582 -0.12543118 -0.0104825  ...  0.12497915  0.12470361\n",
      "  0.13619001]\n",
      "train_accuracy: 0.5371223758320532\n",
      "============== 24800 =================\n",
      "alpha: [-0.09606339 -0.12455238 -0.01674751 ...  0.12503348  0.12005826\n",
      "  0.13770081]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 24900 =================\n",
      "alpha: [-0.09775584 -0.12272431 -0.01520685 ...  0.1283726   0.12408752\n",
      "  0.13549858]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 25000 =================\n",
      "alpha: [-0.1052148  -0.11946853 -0.01537841 ...  0.12678951  0.12142646\n",
      "  0.13093813]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 25100 =================\n",
      "alpha: [-0.09786224 -0.11776853 -0.01313142 ...  0.12147537  0.12321041\n",
      "  0.12999693]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 25200 =================\n",
      "alpha: [-0.10002249 -0.11537629 -0.0118601  ...  0.12112056  0.11904136\n",
      "  0.12571762]\n",
      "train_accuracy: 0.5345622119815668\n",
      "============== 25300 =================\n",
      "alpha: [-0.10536177 -0.11703822 -0.00972093 ...  0.12169402  0.12302911\n",
      "  0.1274363 ]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 25400 =================\n",
      "alpha: [-0.10577323 -0.12019012 -0.00829183 ...  0.11883059  0.12527306\n",
      "  0.13053531]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 25500 =================\n",
      "alpha: [-0.10768561 -0.11998912 -0.01062563 ...  0.12358879  0.12671496\n",
      "  0.12854033]\n",
      "train_accuracy: 0.5345622119815668\n",
      "============== 25600 =================\n",
      "alpha: [-0.10982107 -0.12427372 -0.00962603 ...  0.12517507  0.12470446\n",
      "  0.12972733]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 25700 =================\n",
      "alpha: [-0.11476806 -0.12231068 -0.00815113 ...  0.12413385  0.12360753\n",
      "  0.13311214]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 25800 =================\n",
      "alpha: [-0.11061697 -0.11714473 -0.01042049 ...  0.12613642  0.12014482\n",
      "  0.12968026]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 25900 =================\n",
      "alpha: [-0.11244886 -0.11935513 -0.00956369 ...  0.12062928  0.12470963\n",
      "  0.13338824]\n",
      "train_accuracy: 0.5386584741423451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== 26000 =================\n",
      "alpha: [-0.10838104 -0.11958886 -0.0098364  ...  0.11877331  0.12587034\n",
      "  0.12730034]\n",
      "train_accuracy: 0.5309779825908858\n",
      "============== 26100 =================\n",
      "alpha: [-0.10350444 -0.1223344  -0.01151331 ...  0.11815452  0.12670544\n",
      "  0.13150842]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 26200 =================\n",
      "alpha: [-0.10646023 -0.12734068 -0.0145004  ...  0.12484535  0.12615213\n",
      "  0.12831649]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 26300 =================\n",
      "alpha: [-0.10541697 -0.12787981 -0.01315401 ...  0.12719413  0.12203206\n",
      "  0.12686725]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 26400 =================\n",
      "alpha: [-0.10445145 -0.12390456 -0.0116827  ...  0.12777312  0.12448453\n",
      "  0.1271876 ]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 26500 =================\n",
      "alpha: [-0.10497155 -0.12566253 -0.01125467 ...  0.12762636  0.12189525\n",
      "  0.12676199]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 26600 =================\n",
      "alpha: [-0.10053743 -0.12321555 -0.009447   ...  0.12479359  0.12055487\n",
      "  0.12476112]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 26700 =================\n",
      "alpha: [-0.09252947 -0.12086278 -0.00824595 ...  0.13294953  0.12429705\n",
      "  0.12818016]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 26800 =================\n",
      "alpha: [-0.09110038 -0.12462629 -0.00939949 ...  0.13234075  0.12634895\n",
      "  0.12396134]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 26900 =================\n",
      "alpha: [-0.09789195 -0.12760111 -0.0143752  ...  0.13193552  0.13349479\n",
      "  0.12252849]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 27000 =================\n",
      "alpha: [-0.09754536 -0.12911018 -0.01906031 ...  0.12883369  0.13361751\n",
      "  0.1285895 ]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 27100 =================\n",
      "alpha: [-0.09736287 -0.13092817 -0.02220257 ...  0.12152701  0.13108425\n",
      "  0.12763808]\n",
      "train_accuracy: 0.5345622119815668\n",
      "============== 27200 =================\n",
      "alpha: [-0.09555601 -0.13003662 -0.02315173 ...  0.12674882  0.13250711\n",
      "  0.12242423]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 27300 =================\n",
      "alpha: [-0.09483624 -0.1380366  -0.02077775 ...  0.12789757  0.13363938\n",
      "  0.12571825]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 27400 =================\n",
      "alpha: [-0.09360992 -0.13142886 -0.01897662 ...  0.12462036  0.13825639\n",
      "  0.13007377]\n",
      "train_accuracy: 0.540194572452637\n",
      "============== 27500 =================\n",
      "alpha: [-0.08879769 -0.12960552 -0.01718993 ...  0.12330993  0.14131708\n",
      "  0.13191931]\n",
      "train_accuracy: 0.540194572452637\n",
      "============== 27600 =================\n",
      "alpha: [-0.08667913 -0.13627687 -0.01916159 ...  0.12499213  0.13645924\n",
      "  0.13439424]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 27700 =================\n",
      "alpha: [-0.09138371 -0.13135014 -0.02364199 ...  0.12302966  0.12958673\n",
      "  0.1326381 ]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 27800 =================\n",
      "alpha: [-0.09499771 -0.13101265 -0.02246462 ...  0.12063632  0.12095436\n",
      "  0.13118584]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 27900 =================\n",
      "alpha: [-0.09293407 -0.12802024 -0.02351301 ...  0.11798821  0.11788042\n",
      "  0.13071465]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 28000 =================\n",
      "alpha: [-0.09329479 -0.12479664 -0.02446727 ...  0.11539296  0.12003841\n",
      "  0.13243064]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 28100 =================\n",
      "alpha: [-0.09252233 -0.12446549 -0.02605461 ...  0.119702    0.11896231\n",
      "  0.13382895]\n",
      "train_accuracy: 0.543778801843318\n",
      "============== 28200 =================\n",
      "alpha: [-0.09661406 -0.12240648 -0.02344049 ...  0.11690838  0.11716513\n",
      "  0.13760895]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 28300 =================\n",
      "alpha: [-0.09780234 -0.1246602  -0.01921362 ...  0.11746047  0.11963592\n",
      "  0.12999283]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 28400 =================\n",
      "alpha: [-0.09882193 -0.12633264 -0.01576437 ...  0.1197552   0.12181465\n",
      "  0.12983035]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 28500 =================\n",
      "alpha: [-0.09276839 -0.12995707 -0.01444026 ...  0.1160038   0.12161513\n",
      "  0.1364256 ]\n",
      "train_accuracy: 0.540194572452637\n",
      "============== 28600 =================\n",
      "alpha: [-0.09612652 -0.13288201 -0.0195716  ...  0.11471958  0.11691495\n",
      "  0.13448973]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 28700 =================\n",
      "alpha: [-0.09403764 -0.13621778 -0.01880892 ...  0.11182958  0.11589082\n",
      "  0.12988639]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 28800 =================\n",
      "alpha: [-0.09832576 -0.13221705 -0.02068581 ...  0.11060175  0.11683045\n",
      "  0.13353906]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 28900 =================\n",
      "alpha: [-0.10183861 -0.13473245 -0.02052983 ...  0.11709839  0.12148148\n",
      "  0.13621951]\n",
      "train_accuracy: 0.540194572452637\n",
      "============== 29000 =================\n",
      "alpha: [-0.10121547 -0.13193404 -0.01784849 ...  0.12031782  0.12332292\n",
      "  0.13693612]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 29100 =================\n",
      "alpha: [-0.09986384 -0.13426498 -0.01633314 ...  0.12015416  0.1243856\n",
      "  0.13458151]\n",
      "train_accuracy: 0.540194572452637\n",
      "============== 29200 =================\n",
      "alpha: [-0.10260671 -0.12821032 -0.01590775 ...  0.1238461   0.12454979\n",
      "  0.13362861]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 29300 =================\n",
      "alpha: [-0.09600626 -0.12403691 -0.01453853 ...  0.13133354  0.12757518\n",
      "  0.13235258]\n",
      "train_accuracy: 0.5422427035330261\n",
      "============== 29400 =================\n",
      "alpha: [-0.09395226 -0.12228418 -0.01272859 ...  0.13034868  0.13266176\n",
      "  0.12724029]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 29500 =================\n",
      "alpha: [-0.08832983 -0.12537519 -0.0104627  ...  0.12495321  0.12866399\n",
      "  0.13027311]\n",
      "train_accuracy: 0.5314900153609831\n",
      "============== 29600 =================\n",
      "alpha: [-0.0873378  -0.13004146 -0.00890461 ...  0.12397188  0.13073196\n",
      "  0.12750694]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 29700 =================\n",
      "alpha: [-0.08941936 -0.12895412 -0.00747172 ...  0.12230376  0.12948885\n",
      "  0.12957029]\n",
      "train_accuracy: 0.5407066052227343\n",
      "============== 29800 =================\n",
      "alpha: [-0.09402133 -0.13266223 -0.00640867 ...  0.12381312  0.12765023\n",
      "  0.13327083]\n",
      "train_accuracy: 0.533026113671275\n",
      "============== 29900 =================\n",
      "alpha: [-0.0957317  -0.13117934 -0.01188204 ...  0.12940963  0.12806612\n",
      "  0.12994365]\n",
      "train_accuracy: 0.5371223758320532\n",
      "============== 30000 =================\n",
      "alpha: [-0.09843127 -0.14027691 -0.01272366 ...  0.12875523  0.13468866\n",
      "  0.13536875]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 30100 =================\n",
      "alpha: [-0.09982034 -0.13906061 -0.01198924 ...  0.1301958   0.13391719\n",
      "  0.13895084]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 30200 =================\n",
      "alpha: [-0.09732098 -0.13850541 -0.01115194 ...  0.12681343  0.13236778\n",
      "  0.13550705]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 30300 =================\n",
      "alpha: [-0.09456488 -0.14058009 -0.01263037 ...  0.12596054  0.13260622\n",
      "  0.13795103]\n",
      "train_accuracy: 0.5345622119815668\n",
      "============== 30400 =================\n",
      "alpha: [-0.09676684 -0.13912271 -0.0154805  ...  0.12206546  0.13097667\n",
      "  0.13652215]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 30500 =================\n",
      "alpha: [-0.10174881 -0.13683115 -0.01401837 ...  0.12470208  0.134121\n",
      "  0.13686019]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 30600 =================\n",
      "alpha: [-0.10494655 -0.13659949 -0.01440457 ...  0.12563611  0.1344505\n",
      "  0.13395456]\n",
      "train_accuracy: 0.5412186379928315\n",
      "============== 30700 =================\n",
      "alpha: [-0.10306859 -0.13183099 -0.01518588 ...  0.12634583  0.13433007\n",
      "  0.13763697]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 30800 =================\n",
      "alpha: [-0.10385581 -0.12908123 -0.01390227 ...  0.12439728  0.13306889\n",
      "  0.13181441]\n",
      "train_accuracy: 0.5320020481310804\n",
      "============== 30900 =================\n",
      "alpha: [-0.10053228 -0.13098016 -0.01295825 ...  0.12795943  0.12708415\n",
      "  0.13152621]\n",
      "train_accuracy: 0.540194572452637\n",
      "============== 31000 =================\n",
      "alpha: [-0.09750676 -0.13631777 -0.01327325 ...  0.12407545  0.12526181\n",
      "  0.12757287]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 31100 =================\n",
      "alpha: [-0.09435173 -0.13593722 -0.01238712 ...  0.12069283  0.12531652\n",
      "  0.12431594]\n",
      "train_accuracy: 0.5320020481310804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== 31200 =================\n",
      "alpha: [-0.09302129 -0.13583436 -0.01119076 ...  0.12526169  0.12444984\n",
      "  0.12477511]\n",
      "train_accuracy: 0.5442908346134152\n",
      "============== 31300 =================\n",
      "alpha: [-0.09886917 -0.13369374 -0.01055298 ...  0.12232334  0.12784821\n",
      "  0.12385331]\n",
      "train_accuracy: 0.5314900153609831\n",
      "============== 31400 =================\n",
      "alpha: [-0.09672409 -0.13390055 -0.00949427 ...  0.12561464  0.12916486\n",
      "  0.12423278]\n",
      "train_accuracy: 0.5427547363031234\n",
      "============== 31500 =================\n",
      "alpha: [-0.0987142  -0.1333417  -0.00779848 ...  0.12070196  0.1332375\n",
      "  0.12178588]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 31600 =================\n",
      "alpha: [-0.09661892 -0.12809832 -0.01123013 ...  0.11884619  0.12830845\n",
      "  0.12420751]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 31700 =================\n",
      "alpha: [-0.10008463 -0.12819002 -0.01662073 ...  0.1180798   0.13043777\n",
      "  0.12513898]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 31800 =================\n",
      "alpha: [-0.09943041 -0.1284141  -0.01863891 ...  0.11728864  0.13397903\n",
      "  0.12590714]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 31900 =================\n",
      "alpha: [-0.10286494 -0.1276896  -0.01913764 ...  0.11749114  0.13286621\n",
      "  0.12116415]\n",
      "train_accuracy: 0.5371223758320532\n",
      "============== 32000 =================\n",
      "alpha: [-0.09794263 -0.12513718 -0.02538399 ...  0.11885784  0.12877602\n",
      "  0.12449556]\n",
      "train_accuracy: 0.5396825396825397\n",
      "============== 32100 =================\n",
      "alpha: [-0.0960555  -0.12544251 -0.02617759 ...  0.12084716  0.13160779\n",
      "  0.12269207]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 32200 =================\n",
      "alpha: [-0.09614406 -0.12626983 -0.02296128 ...  0.12136912  0.12696232\n",
      "  0.12182251]\n",
      "train_accuracy: 0.5371223758320532\n",
      "============== 32300 =================\n",
      "alpha: [-0.0938443  -0.1301818  -0.01879794 ...  0.12739504  0.12820925\n",
      "  0.12302666]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 32400 =================\n",
      "alpha: [-0.09437144 -0.13412314 -0.01553448 ...  0.13165814  0.12582047\n",
      "  0.12427857]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 32500 =================\n",
      "alpha: [-0.09125494 -0.12781224 -0.0140562  ...  0.13315629  0.12380741\n",
      "  0.12629468]\n",
      "train_accuracy: 0.5371223758320532\n",
      "============== 32600 =================\n",
      "alpha: [-0.08599985 -0.12944625 -0.01317987 ...  0.13721923  0.13198882\n",
      "  0.12800974]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 32700 =================\n",
      "alpha: [-0.0841708  -0.12759125 -0.0163048  ...  0.12968781  0.13004974\n",
      "  0.12743222]\n",
      "train_accuracy: 0.5355862775217614\n",
      "============== 32800 =================\n",
      "alpha: [-0.08400434 -0.12739591 -0.01530243 ...  0.12717077  0.13363458\n",
      "  0.12898747]\n",
      "train_accuracy: 0.5371223758320532\n",
      "============== 32900 =================\n",
      "alpha: [-0.08236174 -0.12776002 -0.01557021 ...  0.128325    0.12945027\n",
      "  0.13442289]\n",
      "train_accuracy: 0.5381464413722479\n",
      "============== 33000 =================\n",
      "alpha: [-0.08663553 -0.12641146 -0.02008807 ...  0.12876487  0.13502267\n",
      "  0.12928737]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 33100 =================\n",
      "alpha: [-0.08532648 -0.13286002 -0.01775043 ...  0.1235343   0.13705486\n",
      "  0.12514466]\n",
      "train_accuracy: 0.5340501792114696\n",
      "============== 33200 =================\n",
      "alpha: [-0.081441   -0.13067666 -0.01564082 ...  0.12584928  0.13951878\n",
      "  0.12509468]\n",
      "train_accuracy: 0.5376344086021505\n",
      "============== 33300 =================\n",
      "alpha: [-0.08582075 -0.12872398 -0.01835568 ...  0.13015751  0.13792361\n",
      "  0.12508469]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 33400 =================\n",
      "alpha: [-0.08343005 -0.12492294 -0.01667794 ...  0.13167689  0.14000579\n",
      "  0.12475617]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 33500 =================\n",
      "alpha: [-0.08364522 -0.12382367 -0.01518082 ...  0.13598212  0.13787551\n",
      "  0.11989579]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 33600 =================\n",
      "alpha: [-0.09094863 -0.12145437 -0.01839981 ...  0.129729    0.13799068\n",
      "  0.12432049]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 33700 =================\n",
      "alpha: [-0.08906066 -0.12001163 -0.01948501 ...  0.12155164  0.13829345\n",
      "  0.12641823]\n",
      "train_accuracy: 0.536610343061956\n",
      "============== 33800 =================\n",
      "alpha: [-0.08765372 -0.12006286 -0.01737429 ...  0.12031967  0.14033439\n",
      "  0.12343554]\n",
      "train_accuracy: 0.5391705069124424\n",
      "============== 33900 =================\n",
      "alpha: [-0.08659076 -0.12051411 -0.01447296 ...  0.1203707   0.13945089\n",
      "  0.12466436]\n",
      "train_accuracy: 0.5345622119815668\n",
      "============== 34000 =================\n",
      "alpha: [-0.08778375 -0.12039941 -0.01518452 ...  0.12211822  0.14466964\n",
      "  0.12156419]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 34100 =================\n",
      "alpha: [-0.08937894 -0.11802486 -0.01279137 ...  0.12265079  0.14021211\n",
      "  0.12308222]\n",
      "train_accuracy: 0.5345622119815668\n",
      "============== 34200 =================\n",
      "alpha: [-0.08627466 -0.11833559 -0.0121118  ...  0.12579095  0.13661108\n",
      "  0.12428147]\n",
      "train_accuracy: 0.5335381464413722\n",
      "============== 34300 =================\n",
      "alpha: [-0.08539642 -0.11929512 -0.01297914 ...  0.12500151  0.13541842\n",
      "  0.12451197]\n",
      "train_accuracy: 0.5309779825908858\n",
      "============== 34400 =================\n",
      "alpha: [-0.08596488 -0.12236814 -0.01319541 ...  0.12416686  0.13453714\n",
      "  0.12792442]\n",
      "train_accuracy: 0.5360983102918587\n",
      "============== 34500 =================\n",
      "alpha: [-0.08891161 -0.12670695 -0.01238891 ...  0.1251046   0.132375\n",
      "  0.12926889]\n",
      "train_accuracy: 0.5325140809011777\n",
      "============== 34600 =================\n",
      "alpha: [-0.09220455 -0.12727601 -0.01269308 ...  0.13147839  0.13114915\n",
      "  0.13107563]\n",
      "train_accuracy: 0.5386584741423451\n",
      "============== 34700 =================\n",
      "alpha: [-0.09649402 -0.12749069 -0.01271659 ...  0.12783548  0.12718574\n",
      "  0.13008394]\n",
      "train_accuracy: 0.5350742447516641\n",
      "============== 34800 =================\n",
      "alpha: [-0.10126111 -0.12692167 -0.01452381 ...  0.12624091  0.12601768\n",
      "  0.12907049]\n",
      "train_accuracy: 0.5335381464413722\n"
     ]
    }
   ],
   "source": [
    "experiment(linear_kernel, X, y, X_test, y_test, regu_para=0, eta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
